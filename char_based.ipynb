{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"data/askreddit.json\") as json_data:\n",
    "    data_raw = json.load(json_data)\n",
    "\n",
    "data = []\n",
    "\n",
    "# we create a list of comments, where each comment is stored as list of characters\n",
    "for item in data_raw:\n",
    "    # less than 150 character comments are too short for training\n",
    "    if (len(item[\"body\"]) >= 150 and item[\"score\"] > 200):\n",
    "        data.append(list(item[\"body\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all characters\n",
    "characters = []\n",
    "for sublist in data:\n",
    "    for item in sublist:\n",
    "        characters.append(item)\n",
    "\n",
    "characters = sorted(list(set(characters)))\n",
    "n_to_char = {n:char for n, char in enumerate(characters)}\n",
    "char_to_n = {char:n for n, char in enumerate(characters)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\olahk\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "\n",
    "seq_length = 100\n",
    "X = []\n",
    "Y = []\n",
    "# each comment is used as a single piece of text\n",
    "for comment in data:\n",
    "    length = len(comment)\n",
    "    for i in range(0, length-seq_length, 1):\n",
    "        sequence = comment[i:i + seq_length]\n",
    "        label = comment[i + seq_length]\n",
    "        X.append([char_to_n[char] for char in sequence])\n",
    "        Y.append(char_to_n[label])\n",
    "\n",
    "# lstm requires data in the form of (number_of_sequences, length_of_sequence, number_of_features)\n",
    "X_modified = np.reshape(X, (len(X), seq_length, 1))\n",
    "X_modified = X_modified / float(len(characters))\n",
    "# one-hot encoding y values\n",
    "Y_modified = np_utils.to_categorical(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating the training, validation and test data\n",
    "valid_split = 0.2\n",
    "test_split = 0.1\n",
    "sample_size = X_modified.shape[0]\n",
    "\n",
    "X_train = X_modified[0:int(sample_size * (1 - valid_split - test_split))]\n",
    "Y_train = Y_modified[0:int(sample_size * (1 - valid_split - test_split))]\n",
    "X_valid = X_modified[int(sample_size * (1 - valid_split - test_split)):int(sample_size * (1 - test_split))]\n",
    "Y_valid = Y_modified[int(sample_size * (1 - valid_split - test_split)):int(sample_size * (1 - test_split))]\n",
    "X_test  = X_modified[int(sample_size * (1 - test_split)):]\n",
    "Y_test  = Y_modified[int(sample_size * (1 - test_split)):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The LSTM network with 2 hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# an LSTM model that can learn character sequences\n",
    "model = Sequential()\n",
    "model.add(LSTM(400, input_shape=(X_modified.shape[1], X_modified.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(400))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(Y_modified.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model for 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model\n",
    "model.fit(X_train, Y_train,\n",
    "        batch_size = 200,\n",
    "        epochs = 100,\n",
    "        verbose = 2,\n",
    "        validation_data = (X_valid, Y_valid),\n",
    "        shuffle=True)\n",
    "model.save('models/char_based_initial.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create text with the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pineapples do not grow on palm trees. I always thought there were certain types of palm trees that a terily ileck.  Ho was the quietest I've ever seen him watching it. Following the movie he just says \"Damn... I'll just stick with the zombies.\"\n",
      "\n",
      "The way they capture the struggle of survival in the worst situation. The hopelessness and helplessness. How long it takes to die and the drive to survive\n"
     ]
    }
   ],
   "source": [
    "model = load_model('models/char_based_initial.hdf5')\n",
    "# some random reddit comment that is 100 character long, we make our comment from this\n",
    "full_text = list(\"Pineapples do not grow on palm trees. I always thought there were certain types of palm trees that a\")\n",
    "string_mapped = [char_to_n[c] for c in full_text]\n",
    "for i in range(300):\n",
    "        x = np.reshape(string_mapped,(1,len(string_mapped), 1))\n",
    "        x = x / float(len(characters))\n",
    "\n",
    "        pred_index = np.argmax(model.predict(x, verbose=0))\n",
    "        full_text.append(n_to_char[pred_index])\n",
    "\n",
    "        string_mapped.append(pred_index)\n",
    "        string_mapped = string_mapped[1:len(string_mapped)]\n",
    "\n",
    "# the predicted comment\n",
    "print(''.join(full_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model with early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early stopping with saving best model weights\n",
    "early_stopping = EarlyStopping(patience = 10, verbose = 1)\n",
    "checkpointer = ModelCheckpoint(filepath = 'models/char_based_early_stopping.hdf5', save_best_only = True, verbose = 1)\n",
    "# training the model\n",
    "model.fit(X_train, Y_train,\n",
    "        batch_size = 100,\n",
    "        epochs = 1000,\n",
    "        verbose = 2,\n",
    "        callbacks=[checkpointer, early_stopping],\n",
    "        validation_data = (X_valid, Y_valid),\n",
    "        shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create text with the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pineapples do not grow on palm trees. I always thought there were certain types of palm trees that a coua th the mode oe the mole oe the mole oe the mole oe the mole oe the mole oe the mole oe the mole oe the mole oe the mole oe the mole oe the mole oe the mole oe the mole oe the mole oe the mole oe the mole oe the mole oe the mole oe the mole oe the mole oe the mole oe the mole oe the mole oe the\n"
     ]
    }
   ],
   "source": [
    "model = load_model('models/char_based_early_stopping.hdf5')\n",
    "# some random reddit comment that is 100 character long, we make our comment from this\n",
    "full_text = list(\"Pineapples do not grow on palm trees. I always thought there were certain types of palm trees that a\")\n",
    "string_mapped = [char_to_n[c] for c in full_text]\n",
    "for i in range(300):\n",
    "        x = np.reshape(string_mapped,(1,len(string_mapped), 1))\n",
    "        x = x / float(len(characters))\n",
    "\n",
    "        pred_index = np.argmax(model.predict(x, verbose=0))\n",
    "        full_text.append(n_to_char[pred_index])\n",
    "\n",
    "        string_mapped.append(pred_index)\n",
    "        string_mapped = string_mapped[1:len(string_mapped)]\n",
    "\n",
    "# the predicted comment\n",
    "print(''.join(full_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
